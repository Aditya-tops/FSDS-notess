RUNNING NOTES: 19 - MAR - 2025
--------------------------------

1. PREVIOUS TOPIC			-	ML: POLYNOMIAL FEATURE
2. CURRENT TOPIC			-	ML: ONEHOTENCODING + ML
3. UPCOMING TOPIC			-	ML: R VALUE
									         

----------------------------------------------------------------


INDEX
---------

0. DATA SCIENCE DEMO			-	Done

1. DATA SCIENCE FUNDAMENTALS		-	Done

--------------------------------------------------

PYTHON PROGRAMMING LANG
-----------------------

0. PYTHON - INSTALLATION		-	Done

1. PYTHON - INTRODUCTION		-	Done
2. PYTHON - KEYWORDS			-	Done
3. PYTHON - HELLO WORLD PROGRAM		-	Done
4. PYTHON - NAMING CONVENTIONS		-	Done
5. PYTHON - VARIABLES			-	Done
6. PYTHON - DATA TYPES			-	Done
7. PYTHON - OPERATORS			-	Done
8. PYTHON - INPUT & OUTPUT		-	Done
9. PYTHON - FLOW CONTROL		-	Done
10. PYTHON - STRING			-	Done
11. PYTHON - FUNCTIONS - PART - 1	-	Done
12. PYTHON - FUNCTIONS - PART - 2	-	Done
13. PYTHON - MODULE			-	Done
14. PYTHON - PACKAGE			-	Done
15. PYTHON - LIST DATA STRUCUTRE	-	Done
16. PYTHON - TUPLE DATA STRUCUTRE	-	Done
17. PYTHON - SET DATA STRUCUTRE		-	Done
18. PYTHON - DICTIONARY DATA STRUCUTRE	-	Done
19. PYTHON - OBJECT ORIENTED 		-	Done
	PROGRAMMING	

--------------------------------------------------

DATA ANALYSIS				
-------------

1. PANDAS - INTRODUCTION		-	Done
2. PANDAS - SERIES - INTRODUCTION	-	Done
3. PANDAS - NAN VALUE			-	Done
4. PANDAS - SERIES - ATTRIBUTES		-	Done
5. PANDAS - SERIES - METHODS		-	Done
6. PANDAS - DATAFRAME INTRODUCTION	-	Done
7. PANDAS - DATAFRAME - LOADING 	-	Done
	DIFFERENT FILES

8. PANDAS - DATAFRAME - ATTRIBUTES	-	Done
9. PANDAS - DATAFRAME - METHODS		-	Done

10. PANDAS - DATAFRAME - RENAMING 	-	Done
	COLUMN, INDEX

11. PANDAS - DATAFRAME - INPLACE 	-	Done
	PARAMETER

12. PANDAS -DATAFRAME - HANDLING 	-	Done
	MISSING NAN VALUES

13. PANDAS - DATAFRAME - SELECTION 	- 	Done
	LOC, ILOC

14. PANDAS - DATAFRAME - FILTERING	-	Done

15. PANDAS - DATAFRAME - SORTING	-	Done

16. PANDAS - DATAFRAME - GROUPBY	-	Done

17. PANDAS - DATAFRAME - MERGING 	-	Done
	OR JOINING

18. PANDAS - DATAFRAME - CONCAT		-	Done

19. PANDAS - DATAFRAME - ADDING, 	-	Done
	DROPPING ROWS AND COLUMNS

20. PANDAS - DATAFRAME - DATE AND 	-	Done
	TIME OPERATIONS

21. PANDAS - DATAFRAME - CONCATENATING	-	Done 
	MULTIPLE CSV FILES

--------------------------------------------------

DATA ANALYSIS PROJECT
---------------------

1. EDA PROJECT				-	Done

--------------------------------------------------

DATA VISUALIZATION
------------------

1. DATA VISUALIZATION PART 1		-	Done
2. DATA VISUALIZATION PART 2		-	Done
3. DATA VISUALIZATION FUNDAMENTALS	-	Done

4. DATA VISUALIZATION POWER BI		-	Upcoming topic	
		
--------------------------------------------------

NUMPY
-----

1. NUMPY INTRODUCTION			-	Done
2. NUMPY FUNDAMENTALS			-	Done
3. NUMPY ATTRIBUTES			-	Done
4. NUMPY METHODS			-	Done

--------------------------------------------------

MATHS						STATUS
-----						------

1. MATHS - PART - 1 - POPULATION, 	-	Done
	SAMPLE, TYPES OF VARIABLES


2. MATHS - PART - 2 - MODE, MEDIAN, 	-	Done
	MEAN, RANGE, 
	STANDARD DEVIATION, VARIANCE	


3. MATHS - PART - 3 - OUTLIERS		-	Done


4. MATHS - PART - 4 - THE FIVE NUMBERS	-	Done
	SUMMARY, BOX PLOT, OUTLIER


5. MATHS - PART - 5 - SYMMETRY AND 	-	Done
	SKEWNESS


6. MATHS - PART - 6 - EXPLANATORY AND 	-	Done
	RESPONSIVE VARIABLES


7. MATHS - PART - 7 - REGRESSION 	-	Done
	AND R SQUARED


8. MATHS - PART - 8 - RESIDUALS		-	Done


9. MATHS - PART - 9 - THE NORMAL 	-	Hold
	DISTRIBUTION AND 
	68-95-99.7 RULE

10. MATHS - PART - 10 - MATRIX		-	Done

--------------------------------------------------

FEATURE ENGINEERING
-------------------

1. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 1	-	Done


2. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 2	-	Done

--------------------------------------------------

MACHINE LEARNING
----------------

1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	INTRODUCTION

2. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TERMINOLOGY

3. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DATA AND ML ALGORITHMS

4. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LEARNING FUNCTION

5. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TYPES OF MODELS

6. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LIFE CYCLE

7. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TRAIN & TEST DATASETS


8. DATA SCIENCE - MACHINE LEARNING 	- 	Upcoming topic	
	R VALUE


9. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION

9.1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

9.2. DATA SCIENCE - MACHINE LEARNING 	- 	Share
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

10. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	MULTIPLE LINEAR REGRESSION


12. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	PICKLING AND UNPICKLING


13. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SAVE MODEL USING JOBLIB AND 
	PICKLING


10. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	POLYNOMIAL FEATURES

11. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DUMMY VARIABLE, ONEHOTENCODING


12. DATA SCIENCE - MACHINE LEARNING 	-	Running topic
	- R VALUE


--------------------------------------------------

Predefined functions
---------------------

1. print(p)		->	To display the output
2. type(p)		->	To check the data type
3. range(p)		->	To get range of values
4. input(p)		->	To take valut at runtime/dynamically
5. len(p)		->	To find number of values in sequence

6. float(p)		->	To convert to float
7. int(p)		->	To convert to int
8. list(p)		->	Convert from seq to list
9. tuple(p)		->	Convert from seq to tuple
10. set(p)		->	Convert from seq to set

11. dict(p)		->	Convert from list of tups to dict

--------------------------------

Errors
------

1. SyntaxError
2. NameError
3. KeyError
4. ValueError
5. TypeError

6. IndexError
7. IndentationError
8. AttributeError
9. ModuleNotFoundError
10. FileNotFoundError

11. InvalidParameterError

------------------------------------
16. DATA SCIENCE - MACHINE LEARNING 
	DUMMY VARIABLE, 
	ONEHOTENCODING

------------------------------------

ML flow
-------

Data
	DataFrame
		Feature Engg
				Array
					Machine Learning Algorithm
					Cost function
					Gradient Descent Algorithm
						Increase accuracy
						Reduce Error
							Bias
							Variance


ML steps
--------

	1. Importing the libraries
	2. Loading the dataset
	3. Data preparation
	4. Splitting the dataset
	5. Model creation
	6. Model training
	7. Prediction

--------------------------------

Feature Engg

Data having features

Mobile		->	features
smart watch	->	features

--------------------------------

# Steps 1 and 2

print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")


print()
print(df)

--------------------------------

# Getting One hot encoding
# function is updated from get_dummies(df.town) get_dummies(df.town, dtype = int)


print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")




print("Step 3: Data preparation")

dummies = pd.get_dummies(df.town, dtype = int)

print()
print(df)
print()
print(dummies)


--------------------------------

IMP points!!!
-------------

Rule
	input & output		->	Array
	input			->	Column
	output			->	Row

-> Can I break the rule		->	Yes we can
				->	but not a good practice

--------------------------------

# Steps from 1 to 6

print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd
from sklearn.linear_model import LinearRegression





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")




print("Step 3: Data preparation")

dummies = pd.get_dummies(df.town, dtype = int)

merged = pd.concat([df, dummies], axis='columns')
final = merged.drop(['town'], axis = 'columns')


X = final.drop('price', axis = 'columns')
y = final.price





print("Step 4: Splitting dataset: Opt")



print("Step 5: Model creation")

model = LinearRegression()




print("Step 6: Model training")

model.fit(X, y)

--------------------------------

# Prediction

print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd
from sklearn.linear_model import LinearRegression





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")




print("Step 3: Data preparation")

dummies = pd.get_dummies(df.town, dtype = int)

merged = pd.concat([df, dummies], axis='columns')
final = merged.drop(['town'], axis = 'columns')


X = final.drop('price', axis = 'columns')
y = final.price





print("Step 4: Splitting dataset: Opt")



print("Step 5: Model creation")

model = LinearRegression()




print("Step 6: Model training")

model.fit(X.values, y.values)



print("Step 7: Prediction")

print()
print(model.predict([[2600, 1, 0, 0]]))

--------------------------------

-> We are learning Machine learning
-> learning predefined functions, class, methods

read_csv()		->	function

LinearRegression	->	class
fit()			->	method
predict()		->	method

--------------------------------

# Steps from 1 to 7

print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd
from sklearn.linear_model import LinearRegression





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")




print("Step 3: Data preparation")

dummies = pd.get_dummies(df.town, dtype = int)

merged = pd.concat([df, dummies], axis='columns')
final = merged.drop(['town'], axis = 'columns')


X = final.drop('price', axis = 'columns').values
y = final.price.values





print("Step 4: Splitting dataset: Opt")



print("Step 5: Model creation")

model = LinearRegression()




print("Step 6: Model training")

model.fit(X, y)



print("Step 7: Prediction")

print()
print(model.predict(X))

--------------------------------

Father example
--------------

Concern		->	Train his son to recog cat/dog
Data		->	100
Shuffle		->	True
Splitting	->	70:30
70		->	Training
30		->	Testing

Trainging	->	Done

Testing		->	Why
		->	To check the accuracy

30		->	26/30

--------------------------------

# Checking the model score

print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd
from sklearn.linear_model import LinearRegression





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")




print("Step 3: Data preparation")

dummies = pd.get_dummies(df.town, dtype = int)

merged = pd.concat([df, dummies], axis='columns')
final = merged.drop(['town'], axis = 'columns')


X = final.drop('price', axis = 'columns').values
y = final.price.values





print("Step 4: Splitting dataset: Opt")



print("Step 5: Model creation")

model = LinearRegression()




print("Step 6: Model training")

model.fit(X, y)



print("Step 7: Prediction")

print()
print(model.predict(X))


print()
print("Step Spl: Checking score")

print()
print(model.score(X, y)*100)

--------------------------------

Online Team :)	->	Thank you for your resp...

--------------------------------

score	->	Model	->	95

In realtime		->	actual score

			->	Threshold value

model			->	90%

--------------------------------

Father example	->	

Images		->	50 white, black dog, 
		->	50 white, black cat

training	->	done
testing		->	done
		->	got score

Cinema		->	First, white dog	right pred
		->	second	black cat	right pred
		->	third  brown dog
			new data		failed

retraining	->	white, black, brown



cutt off	->	chatGPT
		->	till previsiou + 2021

		->	current affairs: exam failed


--------------------------------

Pipeline	->	We can automate the training

yesterday day	->	trained

today new day	->	batch job:
		->		2am	->	train
				2 to 3 hours

		->	model is ready

--------------------------------

from Iddipilli Karthik (privately):    6:26 PM
how will client know about what code to be used for vijayawada?


from Supriya Rao (privately):    6:26 PM
Sir is there a whatsapp group where we get all updates from naresh it ? 

--------------------------------

Document	->	

Client
	if
		Vijayawada	->	map to	->	

			0, 0, 1		automaticaly

	elif
		Guntur
			0, 1, 0	

	elif
		Gudiwada
			1, 0, 0

--------------------------------

Suggestion
	Python and pandas

		if you are giving some gap, thats okay
		we can understand, later with revision

	Machine learning
		if you have given some gap,
		you can forget ....


--------------------------------

# Prediction

print("Topic: OneHotEncoding with ML")
print()

print("Step 1: Importing the libraries")

import pandas as pd
from sklearn.linear_model import LinearRegression





print("Step 2: Loading the dataset")

df = pd.read_csv("homeprices2.csv")




print("Step 3: Data preparation")

dummies = pd.get_dummies(df.town, dtype = int)

merged = pd.concat([df, dummies], axis='columns')
final = merged.drop(['town'], axis = 'columns')


X = final.drop('price', axis = 'columns').values
y = final.price.values





print("Step 4: Splitting dataset: Opt")



print("Step 5: Model creation")

model = LinearRegression()




print("Step 6: Model training")

model.fit(X, y)



print("Step 7: Prediction")

print()
print(model.predict([[3400, 0, 0, 1]]))

--------------------------------

12. DATA SCIENCE - MACHINE LEARNING 	
	- R VALUE

--------------------------------

r	->	Correlation


Data
	->	linear
	->	non linear


How to recognize either data is linear or non linear

-> By using correlation
-> representing with small r
-> values:	-1	to	+1

--------------------------------

Data1
	Name		Area		Rice packs
	------------------------------------------
	Daniel		1		10
	Prasad		2		20
	Raju		3		30
	Jeswanth	4		40


correlation(Area, Rice packs)	->	0.9
				->	having relationship
				->	linear data


correlation(Name, Ricepacks)	->	0.0

--------------------------------

Data

	c1	c2	c3	c4	target


	Right time to find the relationship between

		columns and target

	We need a topic to explain the relationship

	Correlation

--------------------------------

from Masud Siddiqi (privately):    6:44 PM
If there is no relation between input and output, what model should we use?

-> If no relation then we shouldnot apply the regression model
-> We can atleaset, groupby based on similatires

--------------------------------

R value:
--------

-> We done today session
-> We will connect tomorrow
-> Daniel :-)

--------------------------------

Daily
-----

1. Running notes				->	Sharing
2. Materials (PDF format)			->	Sharing

We are sharing by using 			->	Google classroom

--------------------------------
