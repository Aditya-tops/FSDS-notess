RUNNING NOTES: 21 - MAR - 2025
--------------------------------

1. PREVIOUS TOPIC			-	ML: ONEHOTENCODING + ML
2. CURRENT TOPIC			-	ML: R VALUE
3. UPCOMING TOPIC			-	ML: COST FUNCTION
									         

----------------------------------------------------------------


INDEX
---------

0. DATA SCIENCE DEMO			-	Done

1. DATA SCIENCE FUNDAMENTALS		-	Done

--------------------------------------------------

PYTHON PROGRAMMING LANG
-----------------------

0. PYTHON - INSTALLATION		-	Done

1. PYTHON - INTRODUCTION		-	Done
2. PYTHON - KEYWORDS			-	Done
3. PYTHON - HELLO WORLD PROGRAM		-	Done
4. PYTHON - NAMING CONVENTIONS		-	Done
5. PYTHON - VARIABLES			-	Done
6. PYTHON - DATA TYPES			-	Done
7. PYTHON - OPERATORS			-	Done
8. PYTHON - INPUT & OUTPUT		-	Done
9. PYTHON - FLOW CONTROL		-	Done
10. PYTHON - STRING			-	Done
11. PYTHON - FUNCTIONS - PART - 1	-	Done
12. PYTHON - FUNCTIONS - PART - 2	-	Done
13. PYTHON - MODULE			-	Done
14. PYTHON - PACKAGE			-	Done
15. PYTHON - LIST DATA STRUCUTRE	-	Done
16. PYTHON - TUPLE DATA STRUCUTRE	-	Done
17. PYTHON - SET DATA STRUCUTRE		-	Done
18. PYTHON - DICTIONARY DATA STRUCUTRE	-	Done
19. PYTHON - OBJECT ORIENTED 		-	Done
	PROGRAMMING	

--------------------------------------------------

DATA ANALYSIS				
-------------

1. PANDAS - INTRODUCTION		-	Done
2. PANDAS - SERIES - INTRODUCTION	-	Done
3. PANDAS - NAN VALUE			-	Done
4. PANDAS - SERIES - ATTRIBUTES		-	Done
5. PANDAS - SERIES - METHODS		-	Done
6. PANDAS - DATAFRAME INTRODUCTION	-	Done
7. PANDAS - DATAFRAME - LOADING 	-	Done
	DIFFERENT FILES

8. PANDAS - DATAFRAME - ATTRIBUTES	-	Done
9. PANDAS - DATAFRAME - METHODS		-	Done

10. PANDAS - DATAFRAME - RENAMING 	-	Done
	COLUMN, INDEX

11. PANDAS - DATAFRAME - INPLACE 	-	Done
	PARAMETER

12. PANDAS -DATAFRAME - HANDLING 	-	Done
	MISSING NAN VALUES

13. PANDAS - DATAFRAME - SELECTION 	- 	Done
	LOC, ILOC

14. PANDAS - DATAFRAME - FILTERING	-	Done

15. PANDAS - DATAFRAME - SORTING	-	Done

16. PANDAS - DATAFRAME - GROUPBY	-	Done

17. PANDAS - DATAFRAME - MERGING 	-	Done
	OR JOINING

18. PANDAS - DATAFRAME - CONCAT		-	Done

19. PANDAS - DATAFRAME - ADDING, 	-	Done
	DROPPING ROWS AND COLUMNS

20. PANDAS - DATAFRAME - DATE AND 	-	Done
	TIME OPERATIONS

21. PANDAS - DATAFRAME - CONCATENATING	-	Done 
	MULTIPLE CSV FILES

--------------------------------------------------

DATA ANALYSIS PROJECT
---------------------

1. EDA PROJECT				-	Done

--------------------------------------------------

DATA VISUALIZATION
------------------

1. DATA VISUALIZATION PART 1		-	Done
2. DATA VISUALIZATION PART 2		-	Done
3. DATA VISUALIZATION FUNDAMENTALS	-	Done

4. DATA VISUALIZATION POWER BI		-	Upcoming topic	
		
--------------------------------------------------

NUMPY
-----

1. NUMPY INTRODUCTION			-	Done
2. NUMPY FUNDAMENTALS			-	Done
3. NUMPY ATTRIBUTES			-	Done
4. NUMPY METHODS			-	Done

--------------------------------------------------

MATHS						STATUS
-----						------

1. MATHS - PART - 1 - POPULATION, 	-	Done
	SAMPLE, TYPES OF VARIABLES


2. MATHS - PART - 2 - MODE, MEDIAN, 	-	Done
	MEAN, RANGE, 
	STANDARD DEVIATION, VARIANCE	


3. MATHS - PART - 3 - OUTLIERS		-	Done


4. MATHS - PART - 4 - THE FIVE NUMBERS	-	Done
	SUMMARY, BOX PLOT, OUTLIER


5. MATHS - PART - 5 - SYMMETRY AND 	-	Done
	SKEWNESS


6. MATHS - PART - 6 - EXPLANATORY AND 	-	Done
	RESPONSIVE VARIABLES


7. MATHS - PART - 7 - REGRESSION 	-	Done
	AND R SQUARED


8. MATHS - PART - 8 - RESIDUALS		-	Done


9. MATHS - PART - 9 - THE NORMAL 	-	Hold
	DISTRIBUTION AND 
	68-95-99.7 RULE

10. MATHS - PART - 10 - MATRIX		-	Done

--------------------------------------------------

FEATURE ENGINEERING
-------------------

1. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 1	-	Done


2. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 2	-	Done

--------------------------------------------------

MACHINE LEARNING
----------------

1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	INTRODUCTION

2. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TERMINOLOGY

3. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DATA AND ML ALGORITHMS

4. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LEARNING FUNCTION

5. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TYPES OF MODELS

6. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LIFE CYCLE

7. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TRAIN & TEST DATASETS


8. DATA SCIENCE - MACHINE LEARNING 	- 	Upcoming topic	
	R VALUE


9. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION

9.1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

9.2. DATA SCIENCE - MACHINE LEARNING 	- 	Share
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

10. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	MULTIPLE LINEAR REGRESSION


12. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	PICKLING AND UNPICKLING


13. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SAVE MODEL USING JOBLIB AND 
	PICKLING


10. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	POLYNOMIAL FEATURES

11. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DUMMY VARIABLE, ONEHOTENCODING


12. DATA SCIENCE - MACHINE LEARNING 	-	Done
	- R VALUE

13. DATA SCIENCE - MACHINE LEARNING 	- 	Running topic	
	COST FUNCTION

14. DATA SCIENCE - MACHINE LEARNING 	- 	Upcoming topic	
	REGRESSION COST FUNCTION


--------------------------------------------------

Predefined functions
---------------------

1. print(p)		->	To display the output
2. type(p)		->	To check the data type
3. range(p)		->	To get range of values
4. input(p)		->	To take valut at runtime/dynamically
5. len(p)		->	To find number of values in sequence

6. float(p)		->	To convert to float
7. int(p)		->	To convert to int
8. list(p)		->	Convert from seq to list
9. tuple(p)		->	Convert from seq to tuple
10. set(p)		->	Convert from seq to set

11. dict(p)		->	Convert from list of tups to dict

--------------------------------

Errors
------

1. SyntaxError
2. NameError
3. KeyError
4. ValueError
5. TypeError

6. IndexError
7. IndentationError
8. AttributeError
9. ModuleNotFoundError
10. FileNotFoundError

11. InvalidParameterError

------------------------------------

12. DATA SCIENCE - MACHINE LEARNING 
	- R VALUE

------------------------------------

ML flow
-------

Data
	DataFrame
		Feature Engg
				Array
					Machine Learning Algorithm
					Cost function
					Gradient Descent Algorithm
						Increase accuracy
						Reduce Error
							Bias
							Variance


ML steps
--------

	1. Importing the libraries
	2. Loading the dataset
	3. Data preparation
	4. Splitting the dataset
	5. Model creation
	6. Model training
	7. Prediction

--------------------------------

Linear Regression
-----------------

Data
	1. Linear	->	Apply Linear Regression
	2. Non linear	->	Dont apply linear regression
				check the data


--------------------------------

from Shaik. Manisha Begum (privately):    5:41 PM
sir, in last session you didn't upload the dataset

Sorr for this: I can upload today: Thanks for reminding

--------------------------------

-> If the data is linear, means to say that columns having relationship in between.

-> How to find relationship: By using Correlation(R)

--------------------------------


Correlation(R)
--------------
	
	values:	-1	to	+1

	2 columns	Calculated:	0.9	Strong relation
	2 columns	Calculated:	0.2	weak relation
	2 columns	Calculated:	0.0	No relation

Do we need to calculate manually?

Ans: No, we need to call method....

--------------------------------

# Plotting the data

import pandas as pd
import matplotlib.pyplot as plt

d = {
    "area": [1, 2, 3, 4],
    "rice_yield": [10, 20, 30, 40]
}

df = pd.DataFrame(d)

print(df)

X = df.area.values
y = df.rice_yield.values

plt.xlabel("Area")
plt.ylabel("Rice packs")

plt.scatter(X, y)

plt.show()

--------------------------------

# Checking correlation

import pandas as pd
import matplotlib.pyplot as plt

d = {
    "area": [1, 2, 3, 4],
    "rice_yield": [10, 20, 30, 40]
}

df = pd.DataFrame(d)

result = df.corr()

print(result)

--------------------------------

# Finding correlation

import pandas as pd

d = {
    "a": [600, 3000, 2, 3600, 4],
    "b": [550000, 565000, 610000, 680000, 725000]
}

df = pd.DataFrame(d)

r_value = df.corr()

print(r_value)

--------------------------------

13. DATA SCIENCE - MACHINE LEARNING 	
	COST FUNCTION

--------------------------------

ML flow
-------

Data
	DataFrame
		Feature Engg
				Array
					ML Alg
					Cost function
					Gradient Descent Alg
						Increase accuracy
						Reduce Error
							Bias
							Variance


--------------------------------

...

model.fit()	->	calling
		->	Backend process is HIDDEN/invisible
			in ML
		->	In DL we can see the backend process

--------------------------------

ML flow

Data	
	DataFrame
		Feature Engg
				Array
					ML Alg
					Cost Function
					GDA
					Increase accuracy
					Reduce erros(loss)

Let me run DL example
--------------------
We can see, accuracy is increasing, loss will be reduce....

--------------------------------

Cost functions

-> Optimization techniques
-> 

---->	Hyd---->	KPHB: 	after 8 am
				after 4 pm

Started my bike:	

Example 1:
----------

MCA	->	2007(Joined)
	->	Newtons Engg College, Guntur...

1st Sem		4 hours free time
-------
		Cricket		Study hours

D1		4 hours		0
D2		3.30 hours	30 mins
D3		3.30 hours	30 mins
D4		3.30 hours	30 mins
D5		4 hours		0 mins

Exam time:	little tensed->	done
Results:	All sub passed:	avg marks


2nd Sem		4 hours free time
-------
		Cricket		Study hours

D1		4 hours		0 hours
D2		3 hours		1 hour
D3		2.30 hours	1.30 hours
....
Dlast day	30 mins		3.30 hours


--------------------------------

Example
-------

6th std		->	During schooling, breaks
		->	20 mins

During that time->	Daniel, Vasu, Kesava: 3 

		->	near by: Trees Magoes...



Data1
-----
		Original			Cost function
	Area	Rice packs	Prediction	Error	
	1	10		100		90
	2	20		80		60
	3	30
	4	40

model.fit(Area, Ricepacks)

--------------------------------

1. Supervised learning

1. Regression		->	Having separate cost functions
					1. MSE
					2. RMSE
					3. MAE

2. Classification	->	Having separate cost functions
					Confusion matrix
					Accuracy
					True Positive values
					True Negative....


--------------------------------

Cost function is guiding ml alg to reduce the error

Daniel	->	childhood	->	100 mistakes

Father	->	....		->	2 to 3 mistatkes

--------------------------------

-> We done today session
-> We will connect tomorrow 
-> Daniel :)

--------------------------------

Daily
-----

1. Running notes				->	Sharing
2. Materials (PDF format)			->	Sharing

We are sharing by using 			->	Google classroom

--------------------------------
