RUNNING NOTES: 09 - MAY - 2025
--------------------------------

1. PREVIOUS TOPIC			-	NLP: TF & IDF
2. CURRENT TOPIC			-	NLP: SPACY LIBRARY
3. UPCOMING TOPIC			-	FEW: ML, DL TOPICS
						MODEL DEPLOYMENT
						PROJECTS

----------------------------------------------------------------


INDEX
---------

0. DATA SCIENCE DEMO			-	Done

1. DATA SCIENCE FUNDAMENTALS		-	Done

--------------------------------------------------

PYTHON PROGRAMMING LANG
-----------------------

0. PYTHON - INSTALLATION		-	Done

1. PYTHON - INTRODUCTION		-	Done
2. PYTHON - KEYWORDS			-	Done
3. PYTHON - HELLO WORLD PROGRAM		-	Done
4. PYTHON - NAMING CONVENTIONS		-	Done
5. PYTHON - VARIABLES			-	Done
6. PYTHON - DATA TYPES			-	Done
7. PYTHON - OPERATORS			-	Done
8. PYTHON - INPUT & OUTPUT		-	Done
9. PYTHON - FLOW CONTROL		-	Done
10. PYTHON - STRING			-	Done
11. PYTHON - FUNCTIONS - PART - 1	-	Done
12. PYTHON - FUNCTIONS - PART - 2	-	Done
13. PYTHON - MODULE			-	Done
14. PYTHON - PACKAGE			-	Done
15. PYTHON - LIST DATA STRUCUTRE	-	Done
16. PYTHON - TUPLE DATA STRUCUTRE	-	Done
17. PYTHON - SET DATA STRUCUTRE		-	Done
18. PYTHON - DICTIONARY DATA STRUCUTRE	-	Done
19. PYTHON - OBJECT ORIENTED 		-	Done
	PROGRAMMING	

--------------------------------------------------

DATA ANALYSIS				
-------------

1. PANDAS - INTRODUCTION		-	Done
2. PANDAS - SERIES - INTRODUCTION	-	Done
3. PANDAS - NAN VALUE			-	Done
4. PANDAS - SERIES - ATTRIBUTES		-	Done
5. PANDAS - SERIES - METHODS		-	Done
6. PANDAS - DATAFRAME INTRODUCTION	-	Done
7. PANDAS - DATAFRAME - LOADING 	-	Done
	DIFFERENT FILES

8. PANDAS - DATAFRAME - ATTRIBUTES	-	Done
9. PANDAS - DATAFRAME - METHODS		-	Done

10. PANDAS - DATAFRAME - RENAMING 	-	Done
	COLUMN, INDEX

11. PANDAS - DATAFRAME - INPLACE 	-	Done
	PARAMETER

12. PANDAS -DATAFRAME - HANDLING 	-	Done
	MISSING NAN VALUES

13. PANDAS - DATAFRAME - SELECTION 	- 	Done
	LOC, ILOC

14. PANDAS - DATAFRAME - FILTERING	-	Done

15. PANDAS - DATAFRAME - SORTING	-	Done

16. PANDAS - DATAFRAME - GROUPBY	-	Done

17. PANDAS - DATAFRAME - MERGING 	-	Done
	OR JOINING

18. PANDAS - DATAFRAME - CONCAT		-	Done

19. PANDAS - DATAFRAME - ADDING, 	-	Done
	DROPPING ROWS AND COLUMNS

20. PANDAS - DATAFRAME - DATE AND 	-	Done
	TIME OPERATIONS

21. PANDAS - DATAFRAME - CONCATENATING	-	Done 
	MULTIPLE CSV FILES

--------------------------------------------------

DATA ANALYSIS PROJECT
---------------------

1. EDA PROJECT				-	Done

--------------------------------------------------

DATA VISUALIZATION
------------------

1. DATA VISUALIZATION PART 1		-	Done
2. DATA VISUALIZATION PART 2		-	Done
3. DATA VISUALIZATION FUNDAMENTALS	-	Done

4. DATA VISUALIZATION POWER BI		-	Upcoming topic	
		
--------------------------------------------------

NUMPY
-----

1. NUMPY INTRODUCTION			-	Done
2. NUMPY FUNDAMENTALS			-	Done
3. NUMPY ATTRIBUTES			-	Done
4. NUMPY METHODS			-	Done

--------------------------------------------------

MATHS						STATUS
-----						------

1. MATHS - PART - 1 - POPULATION, 	-	Done
	SAMPLE, TYPES OF VARIABLES


2. MATHS - PART - 2 - MODE, MEDIAN, 	-	Done
	MEAN, RANGE, 
	STANDARD DEVIATION, VARIANCE	


3. MATHS - PART - 3 - OUTLIERS		-	Done


4. MATHS - PART - 4 - THE FIVE NUMBERS	-	Done
	SUMMARY, BOX PLOT, OUTLIER


5. MATHS - PART - 5 - SYMMETRY AND 	-	Done
	SKEWNESS


6. MATHS - PART - 6 - EXPLANATORY AND 	-	Done
	RESPONSIVE VARIABLES


7. MATHS - PART - 7 - REGRESSION 	-	Done
	AND R SQUARED


8. MATHS - PART - 8 - RESIDUALS		-	Done


9. MATHS - PART - 9 - THE NORMAL 	-	Hold
	DISTRIBUTION AND 
	68-95-99.7 RULE

10. MATHS - PART - 10 - MATRIX		-	Done

--------------------------------------------------

FEATURE ENGINEERING
-------------------

1. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 1	-	Done


2. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 2	-	Done

--------------------------------------------------

MACHINE LEARNING
----------------

1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	INTRODUCTION

2. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TERMINOLOGY

3. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DATA AND ML ALGORITHMS

4. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LEARNING FUNCTION

5. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TYPES OF MODELS

6. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LIFE CYCLE

7. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TRAIN & TEST DATASETS


8. DATA SCIENCE - MACHINE LEARNING 	- 	Done	
	R VALUE


9. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION

9.1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

9.2. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

10. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	MULTIPLE LINEAR REGRESSION


11. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	PICKLING AND UNPICKLING


12. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SAVE MODEL USING JOBLIB AND 
	PICKLING


13. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	POLYNOMIAL FEATURES

14. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DUMMY VARIABLE, ONEHOTENCODING


15. DATA SCIENCE - MACHINE LEARNING 	-	Done
	- R VALUE


16. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	COST FUNCTION


17. DATA SCIENCE - MACHINE LEARNING 	- 	Done	
	REGRESSION COST FUNCTION


18. DATA SCIENCE - MACHINE LEARNING 	- 	Done	
	LOGISTIC REGRESSION
	BINARY CLASSIFICATION

19. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LOGISTIC REGRESSION
	MULTI CLASS CLASSIFICATION


20. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DECISION TREE


21. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	RANDOM FOREST ALGORITHM



22. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	K-FOLD CROSS VALIDATION


23. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SVM

24. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	GRADIENT DESCENT ALGORITHM


25. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	UNDERFITTING & OVERFITTING


26. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	BIAS - VARIANCE TRADE OFF


27. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	K - MEANS CLUSTERING


28. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	HYPER PARAMETER TUNING 
	GRIDSEARCH CV


29. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	K NEAREST NEIGHBOR


30. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	XGBOOST

31. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	NAIVE BAYES CLASSIFIER


32. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	CONFUSION MATRIX


33. DATA SCIENCE - MACHINE LEARNING 	- 	Upcoming topic
	LASSO & RIDGE REGRESSION	


34. MODEL DEPLOYMENT			-	Upcoming topic

--------------------------------------------------

DEEP LEARNING
-------------

1. DEEP LEARNING - INTRODUCTION		-	Done
2. DEEP LEARNING - LIBRARIES		-	Done

3. DEEP LEARNING - IMPORTANT 		-	Done
	TERMINOLOGY

4. DEEP LEARNING - MULTILAYER 		-	Done
	PERCEPTRONS

5. DEEP LEARNING - MULTILAYER 		-	Done
	PERCEPTRONS EXAMPLE	

6. DEEP LEARNING - EVALUATE MODEL 	-	Done
	PERFORMANCE	

7. DEEP LEARNING - EVALUATE MODEL 	-	Done
	SAVE MODEL

-  DATA SCIENCE - ENV - PYCHARM		-	Done


8. DEEP LEARNING - BEST MODEL CHECK 	-	Done
	POINT

9. DEEP LEARNING - VISUALIZE MODEL 	-	Done
	ACCURACY & SCORE


--------------------------------------------------

NATURAL LANGUAGE PROCESSING(NLP)
---------------------------

1. NLP - INTRODUCTION			-	Done
2. NLP - TEXT WRANGLING AND CLEANING	-	Done
3. NLP - REPLACING AND CORRECTING WORDS	-	Done
4. NLP - COMPONENTS IN NLP - USE CASE	-	Done

5. NLP - BAG OF WORDS, TF AND IDF	-	Done

6. NLP - TWITTER SENTIMENT ANALYSIS 	-	Done
	USING TEXTBLOB	

7. NLP - SPACY LIBRARRY			-	Done

--------------------------------------------------

Predefined functions
---------------------

1. print(p)		->	To display the output
2. type(p)		->	To check the data type
3. range(p)		->	To get range of values
4. input(p)		->	To take valut at runtime/dynamically
5. len(p)		->	To find number of values in sequence

6. float(p)		->	To convert to float
7. int(p)		->	To convert to int
8. list(p)		->	Convert from seq to list
9. tuple(p)		->	Convert from seq to tuple
10. set(p)		->	Convert from seq to set

11. dict(p)		->	Convert from list of tups to dict

--------------------------------

Errors
------

1. SyntaxError
2. NameError
3. KeyError
4. ValueError
5. TypeError

6. IndexError
7. IndentationError
8. AttributeError
9. ModuleNotFoundError
10. FileNotFoundError

11. InvalidParameterError

------------------------------------

7. NLP - SPACY LIBRARRY
-----------------------

Spacy flow

String
	Doc
		Token
			Attributes

			t.text
			t.is_alpha
			t.is_stop
			t.is_punct
			t.lemma_

------------------------------------

Parts of Speech: By using spacy
-------------------------------

import spacy

a = spacy.load('en_core_web_sm')
b = 'Daniel is singing loudly and his roommates are enjoying too'.lower()
c = a(b)

for t in c:
	print(t, "------->",t.pos_)
    
------------------------------------

# Filtering only verbs


import spacy

a = spacy.load('en_core_web_sm')
b = 'Daniel is singing loudly and his roommates are enjoying too'.lower()
c = a(b)

for t in c:
	if t.pos_ == "VERB":
		print(t)
        
------------------------------------

# Loading text file
# Text file contains, two paragraphs
# Applying Text Analytics by using spacy library

import spacy

a = spacy.load('en_core_web_sm')

with open('covid.txt') as file:
	b = file.read().lower()

c = a(b)

result = [
	t.text
	for t in c
	if not t.is_stop and not t.is_punct
]

print(result)

------------------------------------

# Filtering Nouns and Verbs from paragraph file

import spacy

a = spacy.load('en_core_web_sm')

with open('covid.txt') as file:
    b = file.read().lower()

c = a(b)

result = [
	t1
	for t1 in c
	if not t1.is_stop and not t1.is_punct
]

nouns = [
	t2.text
	for t2 in result 
	if t2.pos_ == "NOUN"
]

verbs = [
	t3.text
	for t3 in result 
	if t3.pos_ == "VERB"
]

print(nouns)
print()
print(verbs)

------------------------------------

# Execute this example only in Google colab

import spacy
from spacy import displacy

a = spacy.load('en_core_web_sm')
b = "Daniel is teaching Python"
c = a(b)

displacy.render(c)

------------------------------------

from Masud Siddiqi (privately):    6:05 PM
why does the model need to know POS?

Model should understand the either its human, action, product

Daniel is teaching	->	Robot
			->	What is the meaning of every word

------------------------------------

NER == Named Entity Recognization
---------------------------------

import spacy

a = spacy.load('en_core_web_sm')
b = 'The building is located at London. It is the headquarters of Google. Mark works there. He speaks English. Daniel is working in Infosys'
c = a(b)

for e in c.ents:
	print(e, "---->",e.label_)
    
------------------------------------

# Displaying only company names

import spacy

a = spacy.load('en_core_web_sm')
b = 'The building is located at London. It is the headquarters of Google. Mark works there. He speaks English. Daniel is working in Infosys'
c = a(b)

for e in c.ents:
	if e.label_ == "ORG":
		print(e)
    
------------------------------------

# Displaying only person names

import spacy

a = spacy.load('en_core_web_sm')
b = 'The building is located at London. It is the headquarters of Google. Mark works there. He speaks English. Daniel is working in Infosys'
c = a(b)

for e in c.ents:
	if e.label_ == "PERSON":
		print(e)
    
------------------------------------

from Supriya Rao (privately):    6:16 PM
we are not using lower() method here so it can identify the names and places?


------------------------------------

from Supriya Rao (privately):    6:17 PM
for example apple is a fruit and Apple is an org right sir

------------------------------------

The topic NER only for
	Companies
	Countries
	States
	Person names
	but not to filter fruits


------------------------------------

# Write and run this example by using Google colab

import spacy
from spacy import displacy

a = spacy.load('en_core_web_sm')
b = 'The building is located at London. It is the headquarters of Google. Mark works there. He speaks English. Daniel is working in Infosys. Matthew is eating banana'
c = a(b)

displacy.render(c, style='ent', jupyter=True)
    
------------------------------------

# Filter fruits from text data

import spacy

# Load spaCy English model
a = spacy.load("en_core_web_sm")

# Sample list of common fruits (you can expand this)
fruit_list = {
    "apple", "banana", "orange", "mango", "grape", "pineapple", "peach",
    "cherry", "pear", "plum", "kiwi", "papaya", "lemon", "lime", "watermelon",
    "blueberry", "strawberry", "raspberry", "coconut", "apricot", "fig", "guava"
}

# Function to extract fruit names
def extract_fruits(b):
    c = a(b)
    found_fruits = set()
    for token in c:
        if token.lemma_.lower() in fruit_list:
            found_fruits.add(token.lemma_.lower())
    return found_fruits

# Sample input
text = """
I love eating mangoes and bananas. Yesterday I bought apples, grapes, and a watermelon.
Steve brought an orange, but he also mentioned Apple Inc. and the new iPhone.
"""

# Run the function
fruits_found = extract_fruits(text)
print("Fruits found:", fruits_found)


------------------------------------

# Recognizing person names

import spacy

a = spacy.load('en_core_web_sm')

b = 'Honoured to serve India, Naredra Modi, 68, wrote in a Twitter post that popped up on the micro blogging site as the ceremony started at 7 p.m. before an audience of 8,000 people, who included United Progressive Alliance chairperson Sonia Gandhi and her son and Congress president Rahul Gandhi, both seated on the front row. Shah, 54, whose inclusion in the cabinet had been much speculated upon, was administered the oaths after Naredra Modi and Rajnath Singh, indicating the order of seniority in the new government , which took office exactly a week after results from the 17th general elections were declared'

c = a(b)

result = [
	t.text
	for t in c
	if t.ent_type_=='PERSON'
]

print(result)

------------------------------------

33. DATA SCIENCE - MACHINE LEARNING 	
	LASSO & RIDGE REGRESSION

------------------------------------

-> To understand lasso & ridge regression, we should know one topic
	Overifitting & Underfitting

-> Overfitting
	During training model is giving high score
	During testing mow lis giving less score


-> Underfitting
	During training model is giving less score
	During testing mow lis giving less score


-> Overfitting: Theory
	This is really problem is machine learning
	Then we need to fix this
	where is the solution:
		Ans: Lasso & Ridge Regression
	

-> Lasso & Ridge regression

	Lasso & Ridge regression are solutions to fix overfitting issue

------------------------------------

-> Why model is facing overfitting issue?

Ans: Due to large coeficient values

-> If dataset having missing values/outliers then we need to handle these then only we need to train the model

------------------------------------

-> We done today session
-> Tomorrow no session
-> We will connect again on Monday
			 - Daniel

------------------------------------

Daily
-----

1. Running notes				->	Sharing
2. Materials (PDF format)			->	Sharing

We are sharing by using 			->	Google classroom

--------------------------------
