RUNNING NOTES: 30 - APRIL - 2025
--------------------------------

1. PREVIOUS TOPIC			-	DL: VISUALIZE ACC & LOSS
2. CURRENT TOPIC			-	NLP: TEXT WRANGLING AND CLEANING
3. UPCOMING TOPIC			-	NLP: REPLACING AND CORRECTING WORDS

----------------------------------------------------------------


INDEX
---------

0. DATA SCIENCE DEMO			-	Done

1. DATA SCIENCE FUNDAMENTALS		-	Done

--------------------------------------------------

PYTHON PROGRAMMING LANG
-----------------------

0. PYTHON - INSTALLATION		-	Done

1. PYTHON - INTRODUCTION		-	Done
2. PYTHON - KEYWORDS			-	Done
3. PYTHON - HELLO WORLD PROGRAM		-	Done
4. PYTHON - NAMING CONVENTIONS		-	Done
5. PYTHON - VARIABLES			-	Done
6. PYTHON - DATA TYPES			-	Done
7. PYTHON - OPERATORS			-	Done
8. PYTHON - INPUT & OUTPUT		-	Done
9. PYTHON - FLOW CONTROL		-	Done
10. PYTHON - STRING			-	Done
11. PYTHON - FUNCTIONS - PART - 1	-	Done
12. PYTHON - FUNCTIONS - PART - 2	-	Done
13. PYTHON - MODULE			-	Done
14. PYTHON - PACKAGE			-	Done
15. PYTHON - LIST DATA STRUCUTRE	-	Done
16. PYTHON - TUPLE DATA STRUCUTRE	-	Done
17. PYTHON - SET DATA STRUCUTRE		-	Done
18. PYTHON - DICTIONARY DATA STRUCUTRE	-	Done
19. PYTHON - OBJECT ORIENTED 		-	Done
	PROGRAMMING	

--------------------------------------------------

DATA ANALYSIS				
-------------

1. PANDAS - INTRODUCTION		-	Done
2. PANDAS - SERIES - INTRODUCTION	-	Done
3. PANDAS - NAN VALUE			-	Done
4. PANDAS - SERIES - ATTRIBUTES		-	Done
5. PANDAS - SERIES - METHODS		-	Done
6. PANDAS - DATAFRAME INTRODUCTION	-	Done
7. PANDAS - DATAFRAME - LOADING 	-	Done
	DIFFERENT FILES

8. PANDAS - DATAFRAME - ATTRIBUTES	-	Done
9. PANDAS - DATAFRAME - METHODS		-	Done

10. PANDAS - DATAFRAME - RENAMING 	-	Done
	COLUMN, INDEX

11. PANDAS - DATAFRAME - INPLACE 	-	Done
	PARAMETER

12. PANDAS -DATAFRAME - HANDLING 	-	Done
	MISSING NAN VALUES

13. PANDAS - DATAFRAME - SELECTION 	- 	Done
	LOC, ILOC

14. PANDAS - DATAFRAME - FILTERING	-	Done

15. PANDAS - DATAFRAME - SORTING	-	Done

16. PANDAS - DATAFRAME - GROUPBY	-	Done

17. PANDAS - DATAFRAME - MERGING 	-	Done
	OR JOINING

18. PANDAS - DATAFRAME - CONCAT		-	Done

19. PANDAS - DATAFRAME - ADDING, 	-	Done
	DROPPING ROWS AND COLUMNS

20. PANDAS - DATAFRAME - DATE AND 	-	Done
	TIME OPERATIONS

21. PANDAS - DATAFRAME - CONCATENATING	-	Done 
	MULTIPLE CSV FILES

--------------------------------------------------

DATA ANALYSIS PROJECT
---------------------

1. EDA PROJECT				-	Done

--------------------------------------------------

DATA VISUALIZATION
------------------

1. DATA VISUALIZATION PART 1		-	Done
2. DATA VISUALIZATION PART 2		-	Done
3. DATA VISUALIZATION FUNDAMENTALS	-	Done

4. DATA VISUALIZATION POWER BI		-	Upcoming topic	
		
--------------------------------------------------

NUMPY
-----

1. NUMPY INTRODUCTION			-	Done
2. NUMPY FUNDAMENTALS			-	Done
3. NUMPY ATTRIBUTES			-	Done
4. NUMPY METHODS			-	Done

--------------------------------------------------

MATHS						STATUS
-----						------

1. MATHS - PART - 1 - POPULATION, 	-	Done
	SAMPLE, TYPES OF VARIABLES


2. MATHS - PART - 2 - MODE, MEDIAN, 	-	Done
	MEAN, RANGE, 
	STANDARD DEVIATION, VARIANCE	


3. MATHS - PART - 3 - OUTLIERS		-	Done


4. MATHS - PART - 4 - THE FIVE NUMBERS	-	Done
	SUMMARY, BOX PLOT, OUTLIER


5. MATHS - PART - 5 - SYMMETRY AND 	-	Done
	SKEWNESS


6. MATHS - PART - 6 - EXPLANATORY AND 	-	Done
	RESPONSIVE VARIABLES


7. MATHS - PART - 7 - REGRESSION 	-	Done
	AND R SQUARED


8. MATHS - PART - 8 - RESIDUALS		-	Done


9. MATHS - PART - 9 - THE NORMAL 	-	Hold
	DISTRIBUTION AND 
	68-95-99.7 RULE

10. MATHS - PART - 10 - MATRIX		-	Done

--------------------------------------------------

FEATURE ENGINEERING
-------------------

1. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 1	-	Done


2. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 2	-	Done

--------------------------------------------------

MACHINE LEARNING
----------------

1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	INTRODUCTION

2. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TERMINOLOGY

3. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DATA AND ML ALGORITHMS

4. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LEARNING FUNCTION

5. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TYPES OF MODELS

6. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LIFE CYCLE

7. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	TRAIN & TEST DATASETS


8. DATA SCIENCE - MACHINE LEARNING 	- 	Done	
	R VALUE


9. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION

9.1. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

9.2. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SIMPLE LINEAR REGRESSION 
	EXAMPLE

10. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	MULTIPLE LINEAR REGRESSION


11. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	PICKLING AND UNPICKLING


12. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SAVE MODEL USING JOBLIB AND 
	PICKLING


13. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	POLYNOMIAL FEATURES

14. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DUMMY VARIABLE, ONEHOTENCODING


15. DATA SCIENCE - MACHINE LEARNING 	-	Done
	- R VALUE


16. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	COST FUNCTION


17. DATA SCIENCE - MACHINE LEARNING 	- 	Done	
	REGRESSION COST FUNCTION


18. DATA SCIENCE - MACHINE LEARNING 	- 	Done	
	LOGISTIC REGRESSION
	BINARY CLASSIFICATION

19. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	LOGISTIC REGRESSION
	MULTI CLASS CLASSIFICATION


20. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	DECISION TREE


21. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	RANDOM FOREST ALGORITHM



22. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	K-FOLD CROSS VALIDATION


23. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	SVM

24. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	GRADIENT DESCENT ALGORITHM


25. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	UNDERFITTING & OVERFITTING


26. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	BIAS - VARIANCE TRADE OFF


27. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	K - MEANS CLUSTERING


28. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	HYPER PARAMETER TUNING 
	GRIDSEARCH CV


29. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	K NEAREST NEIGHBOR


30. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	XGBOOST

31. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	NAIVE BAYES CLASSIFIER


32. DATA SCIENCE - MACHINE LEARNING 	- 	Done
	CONFUSION MATRIX


33. DATA SCIENCE - MACHINE LEARNING 	- 	Upcoming topic
	LASSO & RIDGE REGRESSION	

--------------------------------------------------

DEEP LEARNING
-------------

1. DEEP LEARNING - INTRODUCTION		-	Done
2. DEEP LEARNING - LIBRARIES		-	Done

3. DEEP LEARNING - IMPORTANT 		-	Done
	TERMINOLOGY

4. DEEP LEARNING - MULTILAYER 		-	Done
	PERCEPTRONS

5. DEEP LEARNING - MULTILAYER 		-	Done
	PERCEPTRONS EXAMPLE	

6. DEEP LEARNING - EVALUATE MODEL 	-	Done
	PERFORMANCE	

7. DEEP LEARNING - EVALUATE MODEL 	-	Done
	SAVE MODEL

-  DATA SCIENCE - ENV - PYCHARM		-	Done


8. DEEP LEARNING - BEST MODEL CHECK 	-	Done
	POINT

9. DEEP LEARNING - VISUALIZE MODEL 	-	Running topic
	ACCURACY & SCORE


--------------------------------------------------

NATURAL LANGUAGE PROCESSING(NLP)
---------------------------

1. NLP - INTRODUCTION			-	Done

2. NLP - TEXT WRANGLING AND CLEANING	-	Running topic

3. NLP - REPLACING AND CORRECTING WORDS	-	Upcoming topic


--------------------------------------------------

Predefined functions
---------------------

1. print(p)		->	To display the output
2. type(p)		->	To check the data type
3. range(p)		->	To get range of values
4. input(p)		->	To take valut at runtime/dynamically
5. len(p)		->	To find number of values in sequence

6. float(p)		->	To convert to float
7. int(p)		->	To convert to int
8. list(p)		->	Convert from seq to list
9. tuple(p)		->	Convert from seq to tuple
10. set(p)		->	Convert from seq to set

11. dict(p)		->	Convert from list of tups to dict

--------------------------------

Errors
------

1. SyntaxError
2. NameError
3. KeyError
4. ValueError
5. TypeError

6. IndexError
7. IndentationError
8. AttributeError
9. ModuleNotFoundError
10. FileNotFoundError

11. InvalidParameterError

------------------------------------

2. NLP - TEXT WRANGLING AND CLEANING

----------------------------------------

# split() method in string

text = "Hello Good evening. How are you doing. This is Mr.Daniel and teaching DS & AI at Naresh IT."

print(text)
print()
print(text.split('.'))

----------------------------------------

# sent_tokenize(p) function

from nltk.tokenize import sent_tokenize

text = "Hello Good evening. How are you doing. This is Mr.Daniel and teaching DS & AI at Naresh IT."

print(text)
print()
print(sent_tokenize(text))

----------------------------------------

Tokenization
------------

-> There is a paragraph, Dividing the paragraph into Sentenses and words is called as Tokenization

Two types
---------

-> Word tokenization
	-> Group of words

-> Sentense tokenization
	-> Group of Sentenses

----------------------------------------

Work tokenization: realtime example is chatGPT

-> While we are asking any question to chatGPT, it will apply first operation as word tokenzation

-> What is a python

-> Here 4 words	==	4 tokens

https://platform.openai.com/tokenizer


----------------------------------------

Word tokenization

	1. Lets try by using split() method
	2. Lets try by using nlp technique

----------------------------------------

split() method
--------------
text = "Hello Good evening!!! How are you."
result = text.split()

print(text)
print()
print(result)


-> Split() methods splits based on space separator
-> Its includes special symbols to words :(

----------------------------------------
nlp technique
-------------

from nltk.tokenize import word_tokenize

text = "Hello Good evening!!! How are you."
result = word_tokenize(text)

print(text)
print()
print(result)


-> word_tokenize() predefined function
-> Its splits all words and treating special symbols separately

----------------------------------------

Functions
---------

	1. sent_tokenize()
	2. word_tokenize()

----------------------------------------

# Remove unwanted symbols from text


from nltk.tokenize import regexp_tokenize

text = "Hello #$%#$%Good@#$@#$@# evening!!! How are you."
result = regexp_tokenize(text, pattern = "\w+")

print(text)
print()
print(result)


----------------------------------------

# Extract all numbers from string

from nltk.tokenize import regexp_tokenize

info = "Hello Good evening, this is Daniel and my mobile number is 8095634772 and age is 35 getting 10000 dollars. I am staying in Kaikaluru pin code: 23423423"

result = regexp_tokenize(info, pattern = "\d+")

final = [int(word)         for word in result]

print(info)
print()
print(result)
print()
print(final)

----------------------------------------

details.txt
-----------

This is Sruthi: 8376872634
this is Daniel: 9234798234
this is Raju: 2387492384
this is anju: 239842934
this is Rajesh: 239784239



demo1.py: To extract numbers from file
--------

from nltk.tokenize import regexp_tokenize

data = open("details.txt")
info = data.read()

result = regexp_tokenize(info, pattern = "\d+")
final = [int(word)     for word in result]

for number in final:
	print(number)

----------------------------------------

Functions from nltk

	1. word_tokenize()
	2. sent_tokenize()
	3. regexp_tokenize()

----------------------------------------

Text Analytics
---------------

	1. Load the text data
	2. Tokenization
		word
		sentense
	3. Clean the text
		Filter alphabets
		Filter numbers
		Filter special symbols

	4. Stemming
	5. Lematization

----------------------------------------

# Stemming
-----------

-> Finding the root word from main word

	Going	->	Go
	Talking	->	Talk
	etc


----------------------------------------

from Supriya Rao (privately):    6:23 PM
sir just a query... sometimes bank has numerical & text combined like IFSC code then how will it identify?

Good point: We need to prepara a model

model can analyse/recognize will return

banks.txt
---------

SBI IFCS code:	SBI123
ICICI IFSC code: ICICI123
Axis IFSC code: Axis123

-> Logic: Split the string based on colon symbol then proceed

----------------------------------------

# Stemming for single word

from nltk.stem import PorterStemmer

obj = PorterStemmer()
result = obj.stem("cutting")

print(result)

----------------------------------------

# Stemming for multiple words

from nltk.stem import PorterStemmer

words = ["wait", "waiting", "waited", "waits"]

obj = PorterStemmer()

for word in words:
	print(word, "-------> ",obj.stem(word))
    
    
----------------------------------------

# Limitaion: Stemming works for only basic words
# To overcome this lematinzation

import nltk
from nltk.stem.porter import PorterStemmer

text = "studies studying cries cry"
words = nltk.word_tokenize(text)

obj = PorterStemmer()

for word in words:
	print(word, "---------->", obj.stem(word))
    
----------------------------------------

# Lematization

import nltk
from nltk.stem import WordNetLemmatizer

# If you get LookupError error then enable below code
# nltk.download('wordnet')

text = "studies studying cries cry"
words = nltk.word_tokenize(text)

obj = WordNetLemmatizer()

for word in words:
	print(word, "--------> ", obj.lemmatize(word))

----------------------------------------

7. Stop word removal

-> We done today session
		- Daniel

----------------------------------------

Daily
-----

1. Running notes				->	Sharing
2. Materials (PDF format)			->	Sharing

We are sharing by using 			->	Google classroom

--------------------------------
