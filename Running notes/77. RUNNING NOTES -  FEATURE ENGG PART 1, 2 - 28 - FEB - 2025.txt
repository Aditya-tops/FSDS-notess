RUNNING NOTES: 28 - FEB - 2025
--------------------------------

1. PREVIOUS TOPIC			-	MATHS
2. CURRENT TOPIC			-	FEATURE ENGG PART 1
3. UPCOMING TOPIC			-	FEATURE ENGG PART 2
									         

----------------------------------------------------------------


INDEX
---------

0. DATA SCIENCE DEMO			-	Done

1. DATA SCIENCE FUNDAMENTALS		-	Done

--------------------------------------------------

PYTHON PROGRAMMING LANG
-----------------------

0. PYTHON - INSTALLATION		-	Done

1. PYTHON - INTRODUCTION		-	Done
2. PYTHON - KEYWORDS			-	Done
3. PYTHON - HELLO WORLD PROGRAM		-	Done
4. PYTHON - NAMING CONVENTIONS		-	Done
5. PYTHON - VARIABLES			-	Done
6. PYTHON - DATA TYPES			-	Done
7. PYTHON - OPERATORS			-	Done
8. PYTHON - INPUT & OUTPUT		-	Done
9. PYTHON - FLOW CONTROL		-	Done
10. PYTHON - STRING			-	Done
11. PYTHON - FUNCTIONS - PART - 1	-	Done
12. PYTHON - FUNCTIONS - PART - 2	-	Done
13. PYTHON - MODULE			-	Done
14. PYTHON - PACKAGE			-	Done
15. PYTHON - LIST DATA STRUCUTRE	-	Done
16. PYTHON - TUPLE DATA STRUCUTRE	-	Done
17. PYTHON - SET DATA STRUCUTRE		-	Done
18. PYTHON - DICTIONARY DATA STRUCUTRE	-	Done
19. PYTHON - OBJECT ORIENTED 		-	Done
	PROGRAMMING	

--------------------------------------------------

DATA ANALYSIS				
-------------

1. PANDAS - INTRODUCTION		-	Done
2. PANDAS - SERIES - INTRODUCTION	-	Done
3. PANDAS - NAN VALUE			-	Done
4. PANDAS - SERIES - ATTRIBUTES		-	Done
5. PANDAS - SERIES - METHODS		-	Done
6. PANDAS - DATAFRAME INTRODUCTION	-	Done
7. PANDAS - DATAFRAME - LOADING 	-	Done
	DIFFERENT FILES

8. PANDAS - DATAFRAME - ATTRIBUTES	-	Done
9. PANDAS - DATAFRAME - METHODS		-	Done

10. PANDAS - DATAFRAME - RENAMING 	-	Done
	COLUMN, INDEX

11. PANDAS - DATAFRAME - INPLACE 	-	Done
	PARAMETER

12. PANDAS -DATAFRAME - HANDLING 	-	Done
	MISSING NAN VALUES

13. PANDAS - DATAFRAME - SELECTION 	- 	Done
	LOC, ILOC

14. PANDAS - DATAFRAME - FILTERING	-	Done

15. PANDAS - DATAFRAME - SORTING	-	Done

16. PANDAS - DATAFRAME - GROUPBY	-	Done

17. PANDAS - DATAFRAME - MERGING 	-	Done
	OR JOINING

18. PANDAS - DATAFRAME - CONCAT		-	Done

19. PANDAS - DATAFRAME - ADDING, 	-	Done
	DROPPING ROWS AND COLUMNS

20. PANDAS - DATAFRAME - DATE AND 	-	Done
	TIME OPERATIONS

21. PANDAS - DATAFRAME - CONCATENATING	-	Done 
	MULTIPLE CSV FILES

--------------------------------------------------

DATA ANALYSIS PROJECT
---------------------

1. EDA PROJECT				-	Done

--------------------------------------------------

DATA VISUALIZATION
------------------

1. DATA VISUALIZATION PART 1		-	Done
2. DATA VISUALIZATION PART 2		-	Done
3. DATA VISUALIZATION FUNDAMENTALS	-	Done


4. DATA VISUALIZATION POWER BI		-	Upcoming topic	
		
--------------------------------------------------

NUMPY
-----

1. NUMPY INTRODUCTION			-	Done
2. NUMPY FUNDAMENTALS			-	Done
3. NUMPY ATTRIBUTES			-	Done
4. NUMPY METHODS			-	Done

--------------------------------------------------

MATHS						STATUS
-----						------

1. MATHS - PART - 1 - POPULATION, 	-	Done
	SAMPLE, TYPES OF VARIABLES


2. MATHS - PART - 2 - MODE, MEDIAN, 	-	Done
	MEAN, RANGE, 
	STANDARD DEVIATION, VARIANCE	


3. MATHS - PART - 3 - OUTLIERS		-	Done


4. MATHS - PART - 4 - THE FIVE NUMBERS	-	Done
	SUMMARY, BOX PLOT, OUTLIER


5. MATHS - PART - 5 - SYMMETRY AND 	-	Done
	SKEWNESS


6. MATHS - PART - 6 - EXPLANATORY AND 	-	Done
	RESPONSIVE VARIABLES


7. MATHS - PART - 7 - REGRESSION 	-	Done
	AND R SQUARED


8. MATHS - PART - 8 - RESIDUALS		-	Done


9. MATHS - PART - 9 - THE NORMAL 	-	Hold
	DISTRIBUTION AND 
	68-95-99.7 RULE

10. MATHS - PART - 10 - MATRIX		-	Done

--------------------------------------------------

FEATURE ENGINEERING
-------------------

1. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 1	-	Done


2. FEATURE ENGINEERING - 
	DATA PRE PROCESSING - PART - 2	-	Done

--------------------------------------------------

MACHINE LEARNING
----------------

1. DATA SCIENCE - MACHINE LEARNING 	- 	Running topic
	INTRODUCTION





--------------------------------------------------

Predefined functions
---------------------

1. print(p)		->	To display the output
2. type(p)		->	To check the data type
3. range(p)		->	To get range of values
4. input(p)		->	To take valut at runtime/dynamically
5. len(p)		->	To find number of values in sequence

6. float(p)		->	To convert to float
7. int(p)		->	To convert to int
8. list(p)		->	Convert from seq to list
9. tuple(p)		->	Convert from seq to tuple
10. set(p)		->	Convert from seq to set

11. dict(p)		->	Convert from list of tups to dict

--------------------------------

Errors
------

1. SyntaxError
2. NameError
3. KeyError
4. ValueError
5. TypeError

6. IndexError
7. IndentationError
8. AttributeError
9. ModuleNotFoundError
10. FileNotFoundError

11. InvalidParameterError

--------------------------------

FEATURE ENGG PART 1
-------------------

Data
	DataFrame
	have:NaN
	
		Feature Engg
				Array
					Machine Learning Alg


-------------------

# Imputting missing valus with: mean

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

students = [
	[85, 'M', 'verygood'],
	[95, 'F', 'excellent'],
	[60, np.nan, 'good'],
	[np.nan, 'M', 'average'],
	[70, 'M', 'good'],
	[np.nan, np.nan, 'verygood'],
	[60, 'F', 'verygood'],
	[98, 'M', 'excellent']
]

cols = ['marks', 'gender', 'result']

df = pd.DataFrame(students, columns = cols)

print(df)

imputer = SimpleImputer(
	missing_values = np.nan, 
	strategy = 'mean'
)

result = df[["marks"]].values

df["marks"] = imputer.fit_transform(result)

print()
print(df)

----------------------

How to apply jobs?

1. Naukri	->	Website
2. TCS: careers
3. https://aijobs.net/


----------------------


IMP interview question
----------------------

# stategy should having only 4 values
# InvalidParameterError

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

students = [
	[85, 'M', 'verygood'],
	[95, 'F', 'excellent'],
	[60, np.nan, 'good'],
	[np.nan, 'M', 'average'],
	[70, 'M', 'good'],
	[np.nan, np.nan, 'verygood'],
	[60, 'F', 'verygood'],
	[98, 'M', 'excellent']
]

cols = ['marks', 'gender', 'result']

df = pd.DataFrame(students, columns = cols)

print(df)

imputer = SimpleImputer(
	missing_values = np.nan, 
	strategy = 'nareshit'
)

result = df[["marks"]].values

df["marks"] = imputer.fit_transform(result)

print()
print(df)

----------------------

# strategy = 'median'

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

students = [
	[85, 'M', 'verygood'],
	[95, 'F', 'excellent'],
	[60, np.nan, 'good'],
	[np.nan, 'M', 'average'],
	[70, 'M', 'good'],
	[np.nan, np.nan, 'verygood'],
	[60, 'F', 'verygood'],
	[98, 'M', 'excellent']
]

cols = ['marks', 'gender', 'result']

df = pd.DataFrame(students, columns = cols)

print(df)

imputer = SimpleImputer(
	missing_values = np.nan, 
	strategy = 'median'
)

result = df[["marks"]].values

df["marks"] = imputer.fit_transform(result)

print()
print(df)

----------------------

# strategy = 'most_frequent'

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

students = [
	[85, 'M', 'verygood'],
	[95, 'F', 'excellent'],
	[60, np.nan, 'good'],
	[np.nan, 'M', 'average'],
	[70, 'M', 'good'],
	[np.nan, np.nan, 'verygood'],
	[60, 'F', 'verygood'],
	[98, 'M', 'excellent']
]

cols = ['marks', 'gender', 'result']

df = pd.DataFrame(students, columns = cols)

print(df)

imputer = SimpleImputer(
	missing_values = np.nan, 
	strategy = 'most_frequent'
)

result = df[["marks"]].values

df["marks"] = imputer.fit_transform(result)

print()
print(df)

----------------------

# strategy = 'constant'

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

students = [
	[85, 'M', 'verygood'],
	[95, 'F', 'excellent'],
	[60, np.nan, 'good'],
	[np.nan, 'M', 'average'],
	[70, 'M', 'good'],
	[np.nan, np.nan, 'verygood'],
	[60, 'F', 'verygood'],
	[98, 'M', 'excellent']
]

cols = ['marks', 'gender', 'result']

df = pd.DataFrame(students, columns = cols)

print(df)

imputer = SimpleImputer(
	missing_values = np.nan, 
	strategy = 'constant', 
	fill_value = 80
)

result = df[["marks"]].values

df["marks"] = imputer.fit_transform(result)

print()
print(df)

----------------------

2. FEATURE ENGINEERING - PART - 2
----------------------

# OrdinalEncoder

from numpy import asarray
from sklearn.preprocessing import OrdinalEncoder

a = [['blue'], ['green'], ['red']]

data = asarray(a)

encoder = OrdinalEncoder()
result = encoder.fit_transform(data)

print(data)
print()
print(result)

----------------------

Fruits1
------
		Apple		Pear
Apple		1		0
Pear		0		1
Apple		1		0
Pear		0		1
Apple		1		0

----------------------

Fruits2
-------
	Apple	Banana	Mango

Apple	1	0	0
Mango	0	0	1
Banana	0	1	0

----------------------

colors
------
	blue	green	red
blue	1	0	0
green	0	1	0
red	0	0	1

----------------------

I used DeepSeek

5 q asking

1 times	nicely
2
3
4
5
server is down

----------------------

# OneHotEncoder

from numpy import asarray
from sklearn.preprocessing import OneHotEncoder

a = [['apple'], ['peer'], ['apple'], ['peer'], ['apple']]
data = asarray(a)

print(data)

encoder = OneHotEncoder(sparse_output = False)
onehot = encoder.fit_transform(data)

print()
print(onehot)

----------------------

# OneHotEncoder

from numpy import asarray
from sklearn.preprocessing import OneHotEncoder

a = [['blue'], ['green'], ['red']]
data = asarray(a)

encoder = OneHotEncoder(sparse_output = False)
onehot = encoder.fit_transform(data)

print(data)
print()
print(onehot)

----------------------

# Dummy variable encoding

from numpy import asarray
from sklearn.preprocessing import OneHotEncoder

a = [['blue'], ['green'], ['red']]
data = asarray(a)

encoder = OneHotEncoder(
	drop = 'first',
	sparse_output = False
)

onehot = encoder.fit_transform(data)

print(data)
print()
print(onehot)

----------------------

Interview KIT
-------------


--------------------------------

Daily
-----

1. Running notes				->	Sharing
2. Materials (PDF format)			->	Sharing

We are sharing by using 			->	Google classroom

--------------------------------
